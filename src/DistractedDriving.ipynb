{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DistractedDriving.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QYDpQ4OYCbZH",
        "XEzGVbxICV55",
        "jnWOslWGGNDT",
        "p-L8rN1O4r2E",
        "0vBjTyls588B",
        "lbf_aC6HErjC",
        "cwIpemJgIIBp",
        "MkZrasBkTG0y",
        "4fgGqjdRURXJ",
        "IzPy4CGFKV5p",
        "Ijj2SDfsKsMd",
        "Td4t_u-JUSh_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b0dc43bd7a64d80806563064e8c1f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_afffe0d8f5e848c3b4d4365cca9acfed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eed63864079641dfa6afa1dcbecfc02b",
              "IPY_MODEL_fc94409406ae4dab98f835a66fd6f7b0"
            ]
          }
        },
        "afffe0d8f5e848c3b4d4365cca9acfed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eed63864079641dfa6afa1dcbecfc02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0ab542df89a446fcb1e6eb45c5dc6564",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f8d21ba59dc4be0a0acb6010b615008"
          }
        },
        "fc94409406ae4dab98f835a66fd6f7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0e003852db934d508f28dda1eef40d01",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [5:59:55&lt;00:00, 25.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4dad6e3b14d340d9aa6d0d9fb94c5028"
          }
        },
        "0ab542df89a446fcb1e6eb45c5dc6564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f8d21ba59dc4be0a0acb6010b615008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e003852db934d508f28dda1eef40d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4dad6e3b14d340d9aa6d0d9fb94c5028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nlz8X5XmBv8Z",
        "colab_type": "text"
      },
      "source": [
        "# Distracted Driving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWjhHz6tN7Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_run = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYDpQ4OYCbZH",
        "colab_type": "text"
      },
      "source": [
        "## Reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPZvPoDhWL1s",
        "colab_type": "text"
      },
      "source": [
        "c0 - Safe Driving\n",
        "\n",
        "c1 - Texting (Right)\n",
        "\n",
        "c2 - Talking on Phone (Right)\n",
        "\n",
        "c3 - Texting (Left)\n",
        "\n",
        "c4 - Talking on Phone (Left)\n",
        "\n",
        "c5 - Radio\n",
        "\n",
        "c6 - Drinking\n",
        "\n",
        "c7 - Reaching Behind\n",
        "\n",
        "c8 - Hair and Makeup\n",
        "\n",
        "c9 - Talking to Passenger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEzGVbxICV55",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDuR1W_VKyRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# os.chdir('/content/drive/My Drive/CS 175/Final Project')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import cv2\n",
        "#from google.colab.patches import cv2_imshow as imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "\n",
        "#import timeit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhNBj-IdBpzr",
        "colab_type": "text"
      },
      "source": [
        "# Get Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWOslWGGNDT",
        "colab_type": "text"
      },
      "source": [
        "## Extract FIles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxeEJzn9K1gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if first_run:\n",
        "  !unzip \"/content/drive/My Drive/CS 175/Final Project/state-farm-distracted-driver-detection.zip\" -d \"/content/drive/My Drive/CS 175/Final Project/dset\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do_nuMARbV0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if first_run:\n",
        "  !du \"/content/drive/My Drive/CS 175/Final Project/dset/imgs/\" -h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-L8rN1O4r2E",
        "colab_type": "text"
      },
      "source": [
        "## Load Images with CV2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p3s_Wq03TLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cv2_load(path, size, color_type=3):\n",
        "    if color_type == 1: #Grayscale\n",
        "        img = cv2.imread(path, 0)\n",
        "    elif color_type == 3: #RGB\n",
        "        img = cv2.imread(path)\n",
        "    dim = (int(img.shape[1] * size/100), int(img.shape[0] * size/100)) #Width, Height\n",
        "    img = cv2.resize(img, dim)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeNGMeFDfVXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(train_dataset[0][0].permute(1, 2, 0) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vBjTyls588B",
        "colab_type": "text"
      },
      "source": [
        "### Manually load images\n",
        "Look through csv file and retrieve each image w/ cv2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OZwIEezG0PT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manual = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvNmMLXnv8gS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "if manual:\n",
        "  dataset = pd.read_csv(\"/content/drive/My Drive/CS 175/Final Project/driver_imgs_list.csv\")\n",
        "  dataset.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zV22BjlEkM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if manual:\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "  for classname, img in dataset[['classname', 'img']].iloc:\n",
        "    path = os.path.join('/content', 'drive', 'My Drive', 'CS 175', 'Final Project', 'imgs', 'train', classname, img)\n",
        "    X_train.append(cv2_load(path, 100))\n",
        "    y_train.append(classname)\n",
        "    # print('Path:', path)\n",
        "    # print('CurDir:', os.getcwd())\n",
        "    # print('Dir:', os.path.isdir(path))\n",
        "    # print('File:', os.path.isfile(path))\n",
        "    break\n",
        "  imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y273WOtETR8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if manual:\n",
        "  X_train[0]\n",
        "  train_dataset[0]\n",
        "  # imshow(T.ToPILImage(train_dataset[0][0]))\n",
        "  imshow(train_dataset[0][0].numpy().transpose(2,0,1))\n",
        "  # imshow(np.array(train_dataset[0][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECujkIQZGfEx",
        "colab_type": "text"
      },
      "source": [
        "Need to deal with loading in images to dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbf_aC6HErjC",
        "colab_type": "text"
      },
      "source": [
        "## Load Dataset with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ypSQy2dXWYT",
        "colab_type": "code",
        "outputId": "eb4d1f5c-c047-43fe-9065-7582a105f6ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# /content/drive/My Drive/CS 175/Final Project/dset/imgs/\n",
        "data_path = path = os.path.join('/content', 'drive', 'My Drive', 'CS 175', 'Final Project', 'dset', 'imgs', 'train')\n",
        "# train_dataset = dset.ImageFolder(root=data_path, transform=T.ToTensor())\n",
        "\n",
        "transform = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor(), T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))]) #Processing\n",
        "train_dataset = dset.ImageFolder(root=data_path, transform=transform)\n",
        "\n",
        "len(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22424"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuvccfmM5jG6",
        "colab_type": "text"
      },
      "source": [
        "### Use random_split\n",
        "Doesn't work as a sampler for DataLoader, will come back to make sampler if random sampler doesn't work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1e6OjTdHKo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_split = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdghsi7LUEax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(dataset, split_ratio):\n",
        "  split = int(split_ratio * len(dataset))\n",
        "  return torch.utils.data.random_split(dataset, (split, len(dataset)-split))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JHrQa4MjecK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if random_split:\n",
        "  train_data, val_data = split_data(train_dataset, 0.7)\n",
        "  len(train_data), len(val_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKzvaZeEHOhz",
        "colab_type": "text"
      },
      "source": [
        "pytorch.ipynb\n",
        "```\n",
        "class ChunkSampler(sampler.Sampler):\n",
        "    \"\"\"Samples elements sequentially from some offset. \n",
        "    Arguments:\n",
        "        num_samples: # of desired datapoints\n",
        "        start: offset where we should start selecting from\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples, start = 0):\n",
        "        self.num_samples = num_samples\n",
        "        self.start = start\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.start + self.num_samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "NUM_TRAIN = 49000\n",
        "NUM_VAL = 1000\n",
        "\n",
        "loader_train = DataLoader(train_data, batch_size=64, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
        "loader_val = DataLoader(train_data, batch_size=64, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iEORflB8AD_",
        "colab_type": "text"
      },
      "source": [
        "### Use SubsetRandomSampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS9rvdh6CTPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pytorch.ipynb\n",
        "# loader_train = DataLoader(cifar10_train, batch_size=64, sampler=ChunkSampler(NUM_TRAIN, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOyMAHDYOrvX",
        "colab_type": "text"
      },
      "source": [
        "https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets:\n",
        "```\n",
        "dataset = CustomDatasetFromCSV(my_path)\n",
        "batch_size = 16\n",
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                                sampler=valid_sampler)\n",
        "\n",
        "# Usage Example:\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # Train:   \n",
        "    for batch_index, (faces, labels) in enumerate(train_loader):\n",
        "        # ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QagZ4mOAHmXj",
        "colab_type": "text"
      },
      "source": [
        "Split dataset to training/validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rOzgSib3UBN",
        "colab_type": "code",
        "outputId": "d086d5f8-56a8-49fd-8849-b646c905df9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "split_ratio = 0.2\n",
        "seed = 0\n",
        "bs = 64 #out of mem\n",
        "bs = 1\n",
        "\n",
        "ds_size = len(train_dataset)\n",
        "ind = list(range(ds_size))\n",
        "split = int(split_ratio * ds_size)\n",
        "\n",
        "np.random.seed(seed)\n",
        "np.random.shuffle(ind)\n",
        "train_ind, val_ind = ind[split:], ind[:split]\n",
        "\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=bs, sampler=sampler.SubsetRandomSampler(train_ind))\n",
        "loader_val = torch.utils.data.DataLoader(train_dataset, batch_size=bs, sampler=sampler.SubsetRandomSampler(val_ind))\n",
        "len(loader_train), len(loader_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17940, 4484)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjhIo5Mc6CuQ",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nrV4rNvH0Ao",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch.ipynb\n",
        "Cells from PyTorch.ipynb as framework for training/checking validation and testing old model from CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwIpemJgIIBp",
        "colab_type": "text"
      },
      "source": [
        "### Initialization\n",
        "Define functions etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab7n3SAsYH6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PyTorch.ipynb\n",
        "dtype = torch.FloatTensor # CPU datatype\n",
        "gpu_dtype = torch.cuda.FloatTensor # GPU datatype\n",
        "\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 100\n",
        "\n",
        "# This is a little utility that we'll use to reset the model\n",
        "# if we want to re-initialize all our parameters\n",
        "def reset(m):\n",
        "    if hasattr(m, 'reset_parameters'):\n",
        "        m.reset_parameters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndvb60ulJE4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#modified from PyTorch.ipynb\n",
        "def train(model, loss_fn, optimizer, num_epochs = 1, data_type = gpu_dtype):\n",
        "    for epoch in range(num_epochs):\n",
        "        # print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            x_var = x\n",
        "            y_var = y\n",
        "            # x_var = Variable(x.type(data_type))\n",
        "            # y_var = Variable(y.type(data_type).long())\n",
        "            if data_type == gpu_dtype:\n",
        "              x_var = x_var.cuda()\n",
        "              y_var = y_var.cuda()\n",
        " \n",
        "            scores = model(x_var)\n",
        "            \n",
        "            loss = loss_fn(scores, y_var)\n",
        "            if (t + 1) % print_every == 0:\n",
        "                print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
        " \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crr83uLL_GFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PyTorch.ipynb\n",
        "def check_accuracy(model, loader, data_type = gpu_dtype):\n",
        "    # if loader.dataset.train:\n",
        "    #     print('Checking accuracy on validation set')\n",
        "    # else:\n",
        "    #     print('Checking accuracy on test set')\n",
        "    print('Checking Accuracy')\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
        "    size = len(loader)\n",
        "    percent = 0\n",
        "    for n, (x, y) in enumerate(loader):\n",
        "        if int(100*n/size) > percent:\n",
        "          percent = int(100*n/size)\n",
        "          print(f'{percent}%: {n}/{size}')\n",
        "        with torch.no_grad():\n",
        "            x_var = Variable(x.type(data_type))\n",
        " \n",
        "        scores = model(x_var)\n",
        "        if data_type == gpu_dtype:\n",
        "            _, preds = scores.data.cpu().max(1)\n",
        "        else:\n",
        "            _, preds = scores.data.max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return 100 * acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3lxBpWf-z_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PyTorch.ipynb\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        global first\n",
        "        N, C, H, W = x.size() # read in N, C, H, W\n",
        "        if first == 0:\n",
        "            if debug: print(f'Flatten: {N}x{C}x{H}x{W} -> {N}x{C*H*W}')\n",
        "            first = 1\n",
        "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkZrasBkTG0y",
        "colab_type": "text"
      },
      "source": [
        "### Test my previously model on CIFAR-10\n",
        "Use as reference point for vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP5Dd66mZggN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "old_model = False\n",
        "first = 0\n",
        "debug = False\n",
        "\n",
        "class Size(nn.Module):\n",
        "    def forward(self, x):\n",
        "        global first\n",
        "        size = x.size()\n",
        "        if first == 0:\n",
        "            if debug: print(size)\n",
        "        return x\n",
        "    \n",
        "class Space(nn.Module):\n",
        "    def forward(self, x):\n",
        "        global first\n",
        "        if first == 0:\n",
        "            if debug: print()\n",
        "            first = 1\n",
        "        return x\n",
        "        \n",
        "f1 = 32\n",
        "f2 = f1*2\n",
        "f3 = f2*2\n",
        "s1 = 3\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, f1, s1, padding=1),\n",
        "    nn.ReLU(True),\n",
        "    nn.BatchNorm2d(f1),\n",
        "    nn.Conv2d(f1, f1, s1, padding=1),\n",
        "    nn.ReLU(True),\n",
        "    nn.BatchNorm2d(f1),\n",
        "    nn.MaxPool2d(2,2),\n",
        "    nn.Dropout(0.2),\n",
        "    Size(), #16\n",
        "\n",
        "    nn.Conv2d(f1, f2, s1, padding=1),\n",
        "    nn.ReLU(True),\n",
        "    nn.BatchNorm2d(f2),\n",
        "    nn.Conv2d(f2, f2, s1, padding=1),\n",
        "    nn.ReLU(True),\n",
        "    nn.BatchNorm2d(f2),\n",
        "    nn.MaxPool2d(2,2),\n",
        "    nn.Dropout(0.3),\n",
        "    Size(), #8\n",
        "\n",
        "    nn.Conv2d(f2, f3, s1, padding=1),\n",
        "    nn.ReLU(True),\n",
        "    nn.BatchNorm2d(f3),\n",
        "    nn.Conv2d(f3, f3, s1, padding=1),\n",
        "    nn.ReLU(True),\n",
        "    nn.BatchNorm2d(f3),\n",
        "    nn.MaxPool2d(2,2),\n",
        "    nn.Dropout(0.4),\n",
        "    Size(), #4\n",
        "\n",
        "    Flatten(),\n",
        "    nn.Linear(128*28*28, 1024),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.ReLU(True),\n",
        "    nn.Linear(1024,10),\n",
        "    Space()\n",
        ")\n",
        "\n",
        "\n",
        "loss = nn.CrossEntropyLoss().type(gpu_dtype)\n",
        "opt = optim.RMSprop(model.parameters(), lr=5e-4)\n",
        "\n",
        "if old_model:\n",
        "  model = model.type(gpu_dtype)\n",
        "  model.apply(reset)\n",
        "  train(model, loss, opt, num_epochs=1)\n",
        "  val_acc = check_accuracy(model, loader_val)\n",
        "  print(val_acc)\n",
        "\n",
        "# End Result\n",
        "# Got 2759 / 4484 correct (61.53)\n",
        "# 61.52988403211418"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXl1xL5rIZc7",
        "colab_type": "text"
      },
      "source": [
        "## VGG16\n",
        "Begin looking into VGG16 for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fgGqjdRURXJ",
        "colab_type": "text"
      },
      "source": [
        "### Train vgg16\n",
        "Try training vgg16 from scratch to see performance without transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxZOLIsrUUXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16 = models.vgg16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HJju4KtUO-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "untrained = False\n",
        "model = vgg16\n",
        " \n",
        "loss = nn.CrossEntropyLoss().type(gpu_dtype)\n",
        "opt = optim.RMSprop(model.parameters(), lr=5e-4)\n",
        "if untrained:\n",
        "  model = model.type(gpu_dtype)\n",
        "  model.apply(reset)\n",
        "  train(model, loss, opt, num_epochs=1)\n",
        "  # train_acc = check_accuracy(model, loader_train)\n",
        "  val_acc = check_accuracy(model, loader_val)\n",
        "  print(val_acc)\n",
        "\n",
        "#Low accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEakI7N5TDlT",
        "colab_type": "text"
      },
      "source": [
        "## Test Pretrained vgg16\n",
        "Make use of transfer learning\n",
        "\n",
        "Ref: https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch,\n",
        "\n",
        "https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43Fx3moSS-3Q",
        "colab_type": "code",
        "outputId": "43ecf2d9-9622-455a-bfb5-14fbc9f42bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "0b0dc43bd7a64d80806563064e8c1f3a",
            "afffe0d8f5e848c3b4d4365cca9acfed",
            "eed63864079641dfa6afa1dcbecfc02b",
            "fc94409406ae4dab98f835a66fd6f7b0",
            "0ab542df89a446fcb1e6eb45c5dc6564",
            "0f8d21ba59dc4be0a0acb6010b615008",
            "0e003852db934d508f28dda1eef40d01",
            "4dad6e3b14d340d9aa6d0d9fb94c5028"
          ]
        }
      },
      "source": [
        "pt_vgg16 = models.vgg16(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b0dc43bd7a64d80806563064e8c1f3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzPy4CGFKV5p",
        "colab_type": "text"
      },
      "source": [
        "### Only Replace last linear layer\n",
        "Only replace last linear layer to change output features\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbb6wjj1mjB_",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch\n",
        "```\n",
        "# Load the pretrained model from pytorch\n",
        "vgg16 = models.vgg16_bn()\n",
        "vgg16.load_state_dict(torch.load(\"../input/vgg16bn/vgg16_bn.pth\"))\n",
        "print(vgg16.classifier[6].out_features) # 1000 \n",
        "\n",
        "\n",
        "# Freeze training for all layers\n",
        "for param in vgg16.features.parameters():\n",
        "    param.require_grad = False\n",
        "\n",
        "# Newly created modules have require_grad=True by default\n",
        "num_features = vgg16.classifier[6].in_features\n",
        "features = list(vgg16.classifier.children())[:-1] # Remove last layer\n",
        "features.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with 4 outputs\n",
        "vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n",
        "print(vgg16)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtkhZGmRLSlw",
        "colab_type": "text"
      },
      "source": [
        "Create copy of pretrained vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HeoRlKGLFjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "model = copy.deepcopy(pt_vgg16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDONVvFRm8Dx",
        "colab_type": "text"
      },
      "source": [
        "Freeze weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlljKq54kThi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm5cZtQaJHqZ",
        "colab_type": "code",
        "outputId": "a0e314c9-cbea-40f5-8b19-9926747c8554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model.classifier[6].out_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i3D7oQTJLUH",
        "colab_type": "text"
      },
      "source": [
        "Currently 1000 output features, change last linear layer to have 10 output features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4IjU1dZnowZ",
        "colab_type": "code",
        "outputId": "8453312d-871d-4891-c6a8-c2be9b7c87e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "in_feat = model.classifier[6].in_features\n",
        "features = list(model.classifier.children())[:-1]\n",
        "features.extend([nn.Linear(in_feat, 10)]) #Add layer with 10 class output\n",
        "model.classifier = nn.Sequential(*features)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUtS0TdGSLOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pt_1 = False #Pretrained 1\n",
        "\n",
        "loss = nn.CrossEntropyLoss().type(gpu_dtype)\n",
        "opt = optim.RMSprop(model.parameters(), lr=5e-4)\n",
        "if pt_1:\n",
        "  model = model.type(gpu_dtype)\n",
        "  train(model, loss, opt, num_epochs=1)\n",
        "  val_acc = check_accuracy(model, loader_val)\n",
        "  print(val_acc)\n",
        "\n",
        "\n",
        "# Accuracy: \n",
        "# Got 3820 / 4484 correct (85.19)\n",
        "# 85.19179304192686"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ8-UOiqJnuT",
        "colab_type": "text"
      },
      "source": [
        "### Add new classifier at the end of VGG16\n",
        "Add new classifier after feature identification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyXRTFwlKOQK",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
        "```\n",
        "import torch.nn as nn\n",
        "# Add on classifier\n",
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijj2SDfsKsMd",
        "colab_type": "text"
      },
      "source": [
        "#### Test example classifier above:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jeW6wgbOLZKt"
      },
      "source": [
        "Create copy of pretrained vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VX6aaTa7LZKv",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "model = copy.deepcopy(pt_vgg16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WdE-TIRFLZKz"
      },
      "source": [
        "Freeze weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hzk0DVWuLZK0",
        "colab": {}
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJMfvIe1KoKA",
        "colab_type": "code",
        "outputId": "40cc86fd-624b-42f6-b2b2-ed7cc5d81988",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "in_feat = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(in_feat, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, 10),                   \n",
        "                      nn.LogSoftmax(dim=1))\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Sequential(\n",
            "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.4, inplace=False)\n",
            "      (3): Linear(in_features=256, out_features=10, bias=True)\n",
            "      (4): LogSoftmax()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCduAXn7Mvis",
        "colab_type": "text"
      },
      "source": [
        "Test changed model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjgyBnSWMuQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pt_2 = False #Pretrained 2\n",
        "\n",
        "loss = nn.CrossEntropyLoss().type(gpu_dtype)\n",
        "opt = optim.RMSprop(model.parameters(), lr=5e-4)\n",
        "if pt_2:\n",
        "  model = model.type(gpu_dtype)\n",
        "  train(model, loss, opt, num_epochs=1)\n",
        "  val_acc = check_accuracy(model, loader_val)\n",
        "  print(val_acc)\n",
        "\n",
        "\n",
        "#Accuracy:\n",
        "# Got 3452 / 4484 correct (76.98)\n",
        "# 76.98483496877788"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXODBuMlPHnf",
        "colab_type": "text"
      },
      "source": [
        "changed classifier seems less effective with the sample classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbdYx0SzQkUV",
        "colab_type": "text"
      },
      "source": [
        "### Start Training weights without modified classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-uNB0bpQybM",
        "colab_type": "text"
      },
      "source": [
        "Since the sample classifier seemed to perform worse, I decide to stick with only replacing the last linear layer for output features and training while saving weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iUENERC-RU5q"
      },
      "source": [
        "Create copy of pretrained vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mgeLyjPbRU5s",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "model = copy.deepcopy(pt_vgg16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l01pUbt3RU5w"
      },
      "source": [
        "Freeze weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "seU2qTBbRU5w",
        "colab": {}
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FQenxAgqRU50",
        "outputId": "9deaa56f-cdd4-43e8-ecde-1f3bf12fd112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model.classifier[6].out_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g3w5eXcgRU53"
      },
      "source": [
        "Currently 1000 output features, change last linear layer to have 10 output features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MGCrR_tbRU53",
        "colab": {}
      },
      "source": [
        "in_feat = model.classifier[6].in_features\n",
        "features = list(model.classifier.children())[:-1]\n",
        "features.extend([nn.Linear(in_feat, 10)]) #Add layer with 10 class output\n",
        "model.classifier = nn.Sequential(*features)\n",
        "\n",
        "#print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRpT31XtYwZa",
        "colab_type": "text"
      },
      "source": [
        "Save default model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1BdOjqMYv4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "default_save_path = os.path.join('/content', 'drive', 'My Drive', 'CS 175', 'Final Project', 'default_model.pth')\n",
        "epoch = 0\n",
        "state = {\n",
        "    'epoch': epoch,\n",
        "    'state_dict': model.state_dict(),\n",
        "    'validation': {}\n",
        "}\n",
        "torch.save(state, default_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td4t_u-JUSh_",
        "colab_type": "text"
      },
      "source": [
        "#### Training epochs\n",
        "Start training epochs w/ saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Beh9OL9PRU57",
        "outputId": "8c6f13ba-9fec-4631-a89d-f0fa5ab3f518",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pt_3 = False #Pretrained 3\n",
        "first_run = False\n",
        "save_path = os.path.join('/content', 'drive', 'My Drive', 'CS 175', 'Final Project', 'model.pth')\n",
        "train_epochs = 2 #Number of epochs for this run\n",
        "epoch = 0 #Number of completed epochs\n",
        "\n",
        "if pt_3:\n",
        "  if not first_run: #Load weights if possible\n",
        "    try:\n",
        "      checkpoint = torch.load(save_path)\n",
        "      model.load_state_dict(checkpoint['state_dict'])\n",
        "      epoch = checkpoint['epoch']\n",
        "      print('Weights Loaded')\n",
        "    except Exception as e:\n",
        "      print(f'{e}: Weights Not Loaded')\n",
        "\n",
        "  loss = nn.CrossEntropyLoss().type(gpu_dtype)\n",
        "  opt = optim.RMSprop(model.parameters(), lr=5e-4)\n",
        "\n",
        "  #Train model\n",
        "  model = model.type(gpu_dtype)\n",
        "  train(model, loss, opt, num_epochs=train_epochs)\n",
        "  val_acc = check_accuracy(model, loader_val)\n",
        "\n",
        "  #increment epochs\n",
        "  epoch += train_epochs\n",
        "  print(f'{epoch} epochs: {val_acc}')\n",
        "\n",
        "  #Save weights if wanted\n",
        "  save = input(\"Save Model? (Y/N): \")\n",
        "  if save.lower() == 'y':\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': model.state_dict()\n",
        "    }\n",
        "    torch.save(state, save_path)\n",
        "    print('Saved')\n",
        "  else:\n",
        "    print('Not Saved')\n",
        "\n",
        "\n",
        "#Epoch 1: 84%\n",
        "#Epoch 2: 90%\n",
        "#Epoch 5: 94.4%s"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehLNq6VlBnxd",
        "colab_type": "text"
      },
      "source": [
        "#### Save Validation per epoch\n",
        "Save validation for each epoch for plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar5Papw9BqBy",
        "colab_type": "code",
        "outputId": "211176c3-cdaa-4bd8-e106-f975c5069f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pt_4 = True #Pretrained 4\n",
        "train_epochs = 5 #Number of epochs to train this time\n",
        "\n",
        "#Wrap training to add validation to dict\n",
        "def epoch_train(epoch, validation, model, loss, opt, num_epochs = 1):\n",
        "  for e in range(num_epochs):\n",
        "    print(f'Training epoch {e+1}/{num_epochs}')\n",
        "    train(model, loss, opt, num_epochs=1) #Run 1epoch multiple times\n",
        "    val_acc = check_accuracy(model, loader_val)\n",
        "    epoch += 1\n",
        "    print(f'{epoch} epochs: {val_acc}')\n",
        "    validation[epoch] = val_acc #Add accuracy to validations\n",
        "  return epoch\n",
        "\n",
        "def save_weights(epoch, state_dict, val):\n",
        "  state = {\n",
        "    'epoch': epoch,\n",
        "    'state_dict': model.state_dict(),\n",
        "    'validation': validation\n",
        "  }\n",
        "  torch.save(state, save_path)\n",
        "\n",
        "\n",
        "save_path = os.path.join('/content', 'drive', 'My Drive', 'CS 175', 'Final Project', 'model.pth')\n",
        "default_save_path = os.path.join('/content', 'drive', 'My Drive', 'CS 175', 'Final Project', 'default_model.pth')\n",
        "first_run = False\n",
        "\n",
        "# epoch = 0 #Number of completed epochs\n",
        "# validations = {} #Maps epochs to validation accuracy\n",
        "\n",
        "if pt_4:\n",
        "  if first_run: #Load default vgg16 weights saved earlier\n",
        "    path = default_save_path\n",
        "  else: #Load weights if possible\n",
        "    path = save_path\n",
        "\n",
        "  try: #Load checkpoint data\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    validation = checkpoint['validation']\n",
        "    print('Weights Loaded')\n",
        "  except Exception as e:\n",
        "    print(f'{e}: Weights Not Loaded')\n",
        "    epoch = 0\n",
        "    validation = {}\n",
        "\n",
        "  #Set model to GPU if not already\n",
        "  model = model.type(gpu_dtype)\n",
        "  model.cuda()\n",
        "\n",
        "  loss = nn.CrossEntropyLoss().type(gpu_dtype)\n",
        "  opt = optim.RMSprop(model.parameters(), lr=5e-4)\n",
        "\n",
        "  \n",
        "  #Train model\n",
        "  epoch = epoch_train(epoch, validation, model, loss, opt, num_epochs=train_epochs)\n",
        "\n",
        "  #Save weights if wanted\n",
        "  save = input(\"Save Model? (Y/N): \")\n",
        "  if save.lower() == 'y':\n",
        "    save_weights(epoch, model.state_dict(), validation)\n",
        "    print('Saved')\n",
        "  else:\n",
        "    print('Not Saved')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights Loaded\n",
            "Training epoch 1/5\n",
            "t = 100, loss = 2.9979\n",
            "t = 200, loss = 0.0862\n",
            "t = 300, loss = 0.0000\n",
            "t = 400, loss = 0.0000\n",
            "t = 500, loss = 0.1114\n",
            "t = 600, loss = 0.0012\n",
            "t = 700, loss = 0.0000\n",
            "t = 800, loss = 0.0382\n",
            "t = 900, loss = 0.0060\n",
            "t = 1000, loss = 0.0000\n",
            "t = 1100, loss = 8.8286\n",
            "t = 1200, loss = 7.7052\n",
            "t = 1300, loss = 0.0000\n",
            "t = 1400, loss = 0.0004\n",
            "t = 1500, loss = 0.0000\n",
            "t = 1600, loss = 0.0003\n",
            "t = 1700, loss = 6.3401\n",
            "t = 1800, loss = 0.0002\n",
            "t = 1900, loss = 0.0258\n",
            "t = 2000, loss = 0.0000\n",
            "t = 2100, loss = 0.7343\n",
            "t = 2200, loss = 0.0000\n",
            "t = 2300, loss = 0.6650\n",
            "t = 2400, loss = 0.0000\n",
            "t = 2500, loss = 2.1632\n",
            "t = 2600, loss = 0.0000\n",
            "t = 2700, loss = 0.0000\n",
            "t = 2800, loss = 3.5445\n",
            "t = 2900, loss = 0.0003\n",
            "t = 3000, loss = 0.0001\n",
            "t = 3100, loss = 0.0089\n",
            "t = 3200, loss = 0.0052\n",
            "t = 3300, loss = 0.0000\n",
            "t = 3400, loss = 0.0000\n",
            "t = 3500, loss = 2.7849\n",
            "t = 3600, loss = 0.0056\n",
            "t = 3700, loss = 0.0000\n",
            "t = 3800, loss = 0.0002\n",
            "t = 3900, loss = 3.3421\n",
            "t = 4000, loss = 0.0909\n",
            "t = 4100, loss = 0.0000\n",
            "t = 4200, loss = 1.0599\n",
            "t = 4300, loss = 5.0210\n",
            "t = 4400, loss = 0.0042\n",
            "t = 4500, loss = 0.0381\n",
            "t = 4600, loss = 0.5388\n",
            "t = 4700, loss = 0.0010\n",
            "t = 4800, loss = 1.5811\n",
            "t = 4900, loss = 0.1051\n",
            "t = 5000, loss = 0.0001\n",
            "t = 5100, loss = 0.1425\n",
            "t = 5200, loss = 0.0000\n",
            "t = 5300, loss = 0.0000\n",
            "t = 5400, loss = 0.0018\n",
            "t = 5500, loss = 0.4484\n",
            "t = 5600, loss = 0.0003\n",
            "t = 5700, loss = 0.2524\n",
            "t = 5800, loss = 0.0077\n",
            "t = 5900, loss = 0.0012\n",
            "t = 6000, loss = 0.0000\n",
            "t = 6100, loss = 0.0001\n",
            "t = 6200, loss = 2.5956\n",
            "t = 6300, loss = 1.5020\n",
            "t = 6400, loss = 0.0001\n",
            "t = 6500, loss = 0.0005\n",
            "t = 6600, loss = 0.0000\n",
            "t = 6700, loss = 0.0125\n",
            "t = 6800, loss = 2.2371\n",
            "t = 6900, loss = 0.0000\n",
            "t = 7000, loss = 0.0000\n",
            "t = 7100, loss = 0.1322\n",
            "t = 7200, loss = 0.0021\n",
            "t = 7300, loss = 0.0063\n",
            "t = 7400, loss = 0.0000\n",
            "t = 7500, loss = 8.7003\n",
            "t = 7600, loss = 0.0040\n",
            "t = 7700, loss = 0.0005\n",
            "t = 7800, loss = 0.0000\n",
            "t = 7900, loss = 0.2256\n",
            "t = 8000, loss = 0.0002\n",
            "t = 8100, loss = 1.6284\n",
            "t = 8200, loss = 0.4390\n",
            "t = 8300, loss = 22.2346\n",
            "t = 8400, loss = 8.0757\n",
            "t = 8500, loss = 1.7158\n",
            "t = 8600, loss = 0.6719\n",
            "t = 8700, loss = 0.0109\n",
            "t = 8800, loss = 0.0215\n",
            "t = 8900, loss = 4.9270\n",
            "t = 9000, loss = 8.5941\n",
            "t = 9100, loss = 0.0000\n",
            "t = 9200, loss = 0.0005\n",
            "t = 9300, loss = 0.0000\n",
            "t = 9400, loss = 0.9768\n",
            "t = 9500, loss = 4.7925\n",
            "t = 9600, loss = 0.0032\n",
            "t = 9700, loss = 0.3494\n",
            "t = 9800, loss = 0.0000\n",
            "t = 9900, loss = 0.0000\n",
            "t = 10000, loss = 6.3666\n",
            "t = 10100, loss = 0.0000\n",
            "t = 10200, loss = 0.1658\n",
            "t = 10300, loss = 0.0024\n",
            "t = 10400, loss = 0.0120\n",
            "t = 10500, loss = 0.0002\n",
            "t = 10600, loss = 2.7532\n",
            "t = 10700, loss = 0.0077\n",
            "t = 10800, loss = 5.8098\n",
            "t = 10900, loss = 0.0094\n",
            "t = 11000, loss = 2.0667\n",
            "t = 11100, loss = 0.0031\n",
            "t = 11200, loss = 0.6404\n",
            "t = 11300, loss = 0.0000\n",
            "t = 11400, loss = 0.0000\n",
            "t = 11500, loss = 0.4059\n",
            "t = 11600, loss = 0.5045\n",
            "t = 11700, loss = 0.4765\n",
            "t = 11800, loss = 2.3320\n",
            "t = 11900, loss = 0.0004\n",
            "t = 12000, loss = 0.0009\n",
            "t = 12100, loss = 0.0835\n",
            "t = 12200, loss = 0.0005\n",
            "t = 12300, loss = 0.1850\n",
            "t = 12400, loss = 0.0031\n",
            "t = 12500, loss = 11.9067\n",
            "t = 12600, loss = 0.0037\n",
            "t = 12700, loss = 0.0001\n",
            "t = 12800, loss = 0.0000\n",
            "t = 12900, loss = 1.2073\n",
            "t = 13000, loss = 0.0008\n",
            "t = 13100, loss = 0.9459\n",
            "t = 13200, loss = 0.0000\n",
            "t = 13300, loss = 0.0001\n",
            "t = 13400, loss = 0.0024\n",
            "t = 13500, loss = 0.0558\n",
            "t = 13600, loss = 0.0000\n",
            "t = 13700, loss = 0.2018\n",
            "t = 13800, loss = 0.0001\n",
            "t = 13900, loss = 0.0025\n",
            "t = 14000, loss = 0.0048\n",
            "t = 14100, loss = 0.8187\n",
            "t = 14200, loss = 4.9967\n",
            "t = 14300, loss = 0.0018\n",
            "t = 14400, loss = 0.0000\n",
            "t = 14500, loss = 0.1487\n",
            "t = 14600, loss = 0.0000\n",
            "t = 14700, loss = 5.9861\n",
            "t = 14800, loss = 2.8197\n",
            "t = 14900, loss = 1.6477\n",
            "t = 15000, loss = 0.0003\n",
            "t = 15100, loss = 0.0002\n",
            "t = 15200, loss = 0.0594\n",
            "t = 15300, loss = 14.9821\n",
            "t = 15400, loss = 0.0001\n",
            "t = 15500, loss = 1.1823\n",
            "t = 15600, loss = 5.5038\n",
            "t = 15700, loss = 0.0001\n",
            "t = 15800, loss = 0.0028\n",
            "t = 15900, loss = 0.0195\n",
            "t = 16000, loss = 0.0062\n",
            "t = 16100, loss = 0.0338\n",
            "t = 16200, loss = 0.0000\n",
            "t = 16300, loss = 0.0000\n",
            "t = 16400, loss = 0.0000\n",
            "t = 16500, loss = 2.0270\n",
            "t = 16600, loss = 0.2709\n",
            "t = 16700, loss = 0.8443\n",
            "t = 16800, loss = 7.2355\n",
            "t = 16900, loss = 0.0392\n",
            "t = 17000, loss = 0.0000\n",
            "t = 17100, loss = 0.0043\n",
            "t = 17200, loss = 0.0000\n",
            "t = 17300, loss = 0.6992\n",
            "t = 17400, loss = 0.0442\n",
            "t = 17500, loss = 0.0410\n",
            "t = 17600, loss = 2.2794\n",
            "t = 17700, loss = 0.0012\n",
            "t = 17800, loss = 3.6752\n",
            "t = 17900, loss = 0.0000\n",
            "Checking Accuracy\n",
            "1%: 45/4484\n",
            "2%: 90/4484\n",
            "3%: 135/4484\n",
            "4%: 180/4484\n",
            "5%: 225/4484\n",
            "6%: 270/4484\n",
            "7%: 314/4484\n",
            "8%: 359/4484\n",
            "9%: 404/4484\n",
            "10%: 449/4484\n",
            "11%: 494/4484\n",
            "12%: 539/4484\n",
            "13%: 583/4484\n",
            "14%: 628/4484\n",
            "15%: 673/4484\n",
            "16%: 718/4484\n",
            "17%: 763/4484\n",
            "18%: 808/4484\n",
            "19%: 852/4484\n",
            "20%: 897/4484\n",
            "21%: 942/4484\n",
            "22%: 987/4484\n",
            "23%: 1032/4484\n",
            "24%: 1077/4484\n",
            "25%: 1121/4484\n",
            "26%: 1166/4484\n",
            "27%: 1211/4484\n",
            "28%: 1256/4484\n",
            "29%: 1301/4484\n",
            "30%: 1346/4484\n",
            "31%: 1391/4484\n",
            "32%: 1435/4484\n",
            "33%: 1480/4484\n",
            "34%: 1525/4484\n",
            "35%: 1570/4484\n",
            "36%: 1615/4484\n",
            "37%: 1660/4484\n",
            "38%: 1704/4484\n",
            "39%: 1749/4484\n",
            "40%: 1794/4484\n",
            "41%: 1839/4484\n",
            "42%: 1884/4484\n",
            "43%: 1929/4484\n",
            "44%: 1973/4484\n",
            "45%: 2018/4484\n",
            "46%: 2063/4484\n",
            "47%: 2108/4484\n",
            "48%: 2153/4484\n",
            "49%: 2198/4484\n",
            "50%: 2242/4484\n",
            "51%: 2287/4484\n",
            "52%: 2332/4484\n",
            "53%: 2377/4484\n",
            "54%: 2422/4484\n",
            "55%: 2467/4484\n",
            "56%: 2512/4484\n",
            "57%: 2556/4484\n",
            "58%: 2601/4484\n",
            "59%: 2646/4484\n",
            "60%: 2691/4484\n",
            "61%: 2736/4484\n",
            "62%: 2781/4484\n",
            "63%: 2825/4484\n",
            "64%: 2870/4484\n",
            "65%: 2915/4484\n",
            "66%: 2960/4484\n",
            "67%: 3005/4484\n",
            "68%: 3050/4484\n",
            "69%: 3094/4484\n",
            "70%: 3139/4484\n",
            "71%: 3184/4484\n",
            "72%: 3229/4484\n",
            "73%: 3274/4484\n",
            "74%: 3319/4484\n",
            "75%: 3363/4484\n",
            "76%: 3408/4484\n",
            "77%: 3453/4484\n",
            "78%: 3498/4484\n",
            "79%: 3543/4484\n",
            "80%: 3588/4484\n",
            "81%: 3633/4484\n",
            "82%: 3677/4484\n",
            "83%: 3722/4484\n",
            "84%: 3767/4484\n",
            "85%: 3812/4484\n",
            "86%: 3857/4484\n",
            "87%: 3902/4484\n",
            "88%: 3946/4484\n",
            "89%: 3991/4484\n",
            "90%: 4036/4484\n",
            "91%: 4081/4484\n",
            "92%: 4126/4484\n",
            "93%: 4171/4484\n",
            "94%: 4215/4484\n",
            "95%: 4260/4484\n",
            "96%: 4305/4484\n",
            "97%: 4350/4484\n",
            "98%: 4395/4484\n",
            "99%: 4440/4484\n",
            "Got 4241 / 4484 correct (94.58)\n",
            "11 epochs: 94.5807314897413\n",
            "Training epoch 2/5\n",
            "t = 100, loss = 1.2019\n",
            "t = 200, loss = 0.0000\n",
            "t = 300, loss = 0.0272\n",
            "t = 400, loss = 0.0049\n",
            "t = 500, loss = 0.0043\n",
            "t = 600, loss = 0.0029\n",
            "t = 700, loss = 0.0000\n",
            "t = 800, loss = 0.0000\n",
            "t = 900, loss = 0.0067\n",
            "t = 1000, loss = 0.6835\n",
            "t = 1100, loss = 2.3338\n",
            "t = 1200, loss = 0.0124\n",
            "t = 1300, loss = 0.0006\n",
            "t = 1400, loss = 0.0000\n",
            "t = 1500, loss = 13.1339\n",
            "t = 1600, loss = 3.0875\n",
            "t = 1700, loss = 0.3479\n",
            "t = 1800, loss = 4.7102\n",
            "t = 1900, loss = 0.0002\n",
            "t = 2000, loss = 0.1136\n",
            "t = 2100, loss = 0.0016\n",
            "t = 2200, loss = 0.1288\n",
            "t = 2300, loss = 0.0000\n",
            "t = 2400, loss = 0.0076\n",
            "t = 2500, loss = 0.0000\n",
            "t = 2600, loss = 0.0001\n",
            "t = 2700, loss = 0.0001\n",
            "t = 2800, loss = 0.0000\n",
            "t = 2900, loss = 0.0000\n",
            "t = 3000, loss = 4.0042\n",
            "t = 3100, loss = 0.0745\n",
            "t = 3200, loss = 0.5679\n",
            "t = 3300, loss = 0.0010\n",
            "t = 3400, loss = 0.0055\n",
            "t = 3500, loss = 0.0167\n",
            "t = 3600, loss = 0.0001\n",
            "t = 3700, loss = 12.3022\n",
            "t = 3800, loss = 0.0000\n",
            "t = 3900, loss = 0.0247\n",
            "t = 4000, loss = 2.1013\n",
            "t = 4100, loss = 0.9172\n",
            "t = 4200, loss = 0.0004\n",
            "t = 4300, loss = 0.0264\n",
            "t = 4400, loss = 5.8653\n",
            "t = 4500, loss = 9.1157\n",
            "t = 4600, loss = 0.0010\n",
            "t = 4700, loss = 0.0000\n",
            "t = 4800, loss = 0.0016\n",
            "t = 4900, loss = 0.0000\n",
            "t = 5000, loss = 0.0742\n",
            "t = 5100, loss = 0.0048\n",
            "t = 5200, loss = 0.0004\n",
            "t = 5300, loss = 0.0538\n",
            "t = 5400, loss = 0.0049\n",
            "t = 5500, loss = 1.2003\n",
            "t = 5600, loss = 0.0000\n",
            "t = 5700, loss = 0.0002\n",
            "t = 5800, loss = 0.7391\n",
            "t = 5900, loss = 0.0000\n",
            "t = 6000, loss = 0.0001\n",
            "t = 6100, loss = 0.0024\n",
            "t = 6200, loss = 0.0018\n",
            "t = 6300, loss = 0.1820\n",
            "t = 6400, loss = 0.0000\n",
            "t = 6500, loss = 0.0374\n",
            "t = 6600, loss = 4.7331\n",
            "t = 6700, loss = 0.0245\n",
            "t = 6800, loss = 0.0000\n",
            "t = 6900, loss = 0.5386\n",
            "t = 7000, loss = 0.0000\n",
            "t = 7100, loss = 0.0217\n",
            "t = 7200, loss = 1.7394\n",
            "t = 7300, loss = 0.0000\n",
            "t = 7400, loss = 0.0419\n",
            "t = 7500, loss = 0.0600\n",
            "t = 7600, loss = 0.0034\n",
            "t = 7700, loss = 0.0000\n",
            "t = 7800, loss = 0.0000\n",
            "t = 7900, loss = 0.0000\n",
            "t = 8000, loss = 0.0000\n",
            "t = 8100, loss = 0.0001\n",
            "t = 8200, loss = 0.4669\n",
            "t = 8300, loss = 0.1710\n",
            "t = 8400, loss = 0.1116\n",
            "t = 8500, loss = 0.2679\n",
            "t = 8600, loss = 1.6067\n",
            "t = 8700, loss = 0.0067\n",
            "t = 8800, loss = 0.4138\n",
            "t = 8900, loss = 0.0004\n",
            "t = 9000, loss = 0.0000\n",
            "t = 9100, loss = 0.0049\n",
            "t = 9200, loss = 0.0061\n",
            "t = 9300, loss = 0.7311\n",
            "t = 9400, loss = 0.0004\n",
            "t = 9500, loss = 2.3552\n",
            "t = 9600, loss = 1.6766\n",
            "t = 9700, loss = 0.0004\n",
            "t = 9800, loss = 0.0000\n",
            "t = 9900, loss = 1.2333\n",
            "t = 10000, loss = 0.0004\n",
            "t = 10100, loss = 0.0720\n",
            "t = 10200, loss = 0.0048\n",
            "t = 10300, loss = 0.0042\n",
            "t = 10400, loss = 0.0000\n",
            "t = 10500, loss = 0.0659\n",
            "t = 10600, loss = 0.0163\n",
            "t = 10700, loss = 0.0107\n",
            "t = 10800, loss = 1.3705\n",
            "t = 10900, loss = 2.8132\n",
            "t = 11000, loss = 0.0000\n",
            "t = 11100, loss = 0.0000\n",
            "t = 11200, loss = 0.4778\n",
            "t = 11300, loss = 4.3641\n",
            "t = 11400, loss = 0.9633\n",
            "t = 11500, loss = 0.0034\n",
            "t = 11600, loss = 0.0005\n",
            "t = 11700, loss = 0.0000\n",
            "t = 11800, loss = 0.0000\n",
            "t = 11900, loss = 1.5381\n",
            "t = 12000, loss = 5.2611\n",
            "t = 12100, loss = 5.5687\n",
            "t = 12200, loss = 0.0000\n",
            "t = 12300, loss = 0.0001\n",
            "t = 12400, loss = 0.0406\n",
            "t = 12500, loss = 0.0001\n",
            "t = 12600, loss = 0.0015\n",
            "t = 12700, loss = 0.0001\n",
            "t = 12800, loss = 0.0000\n",
            "t = 12900, loss = 7.7664\n",
            "t = 13000, loss = 4.9719\n",
            "t = 13100, loss = 0.0029\n",
            "t = 13200, loss = 0.0062\n",
            "t = 13300, loss = 0.0013\n",
            "t = 13400, loss = 0.9175\n",
            "t = 13500, loss = 4.6866\n",
            "t = 13600, loss = 0.1392\n",
            "t = 13700, loss = 0.0444\n",
            "t = 13800, loss = 2.1620\n",
            "t = 13900, loss = 0.0000\n",
            "t = 14000, loss = 0.0001\n",
            "t = 14100, loss = 0.0047\n",
            "t = 14200, loss = 0.0115\n",
            "t = 14300, loss = 0.0009\n",
            "t = 14400, loss = 1.8168\n",
            "t = 14500, loss = 0.0004\n",
            "t = 14600, loss = 0.3223\n",
            "t = 14700, loss = 0.0001\n",
            "t = 14800, loss = 1.3293\n",
            "t = 14900, loss = 0.2239\n",
            "t = 15000, loss = 0.0012\n",
            "t = 15100, loss = 4.7708\n",
            "t = 15200, loss = 0.0000\n",
            "t = 15300, loss = 0.0093\n",
            "t = 15400, loss = 0.0609\n",
            "t = 15500, loss = 0.0100\n",
            "t = 15600, loss = 1.7711\n",
            "t = 15700, loss = 0.0001\n",
            "t = 15800, loss = 0.0410\n",
            "t = 15900, loss = 4.3731\n",
            "t = 16000, loss = 1.3354\n",
            "t = 16100, loss = 0.0000\n",
            "t = 16200, loss = 0.0002\n",
            "t = 16300, loss = 0.0008\n",
            "t = 16400, loss = 3.7868\n",
            "t = 16500, loss = 5.0387\n",
            "t = 16600, loss = 0.1482\n",
            "t = 16700, loss = 0.1324\n",
            "t = 16800, loss = 4.0449\n",
            "t = 16900, loss = 0.7380\n",
            "t = 17000, loss = 0.0002\n",
            "t = 17100, loss = 0.0001\n",
            "t = 17200, loss = 0.0002\n",
            "t = 17300, loss = 0.0000\n",
            "t = 17400, loss = 0.0013\n",
            "t = 17500, loss = 3.2080\n",
            "t = 17600, loss = 14.1188\n",
            "t = 17700, loss = 0.0015\n",
            "t = 17800, loss = 0.0000\n",
            "t = 17900, loss = 0.0431\n",
            "Checking Accuracy\n",
            "1%: 45/4484\n",
            "2%: 90/4484\n",
            "3%: 135/4484\n",
            "4%: 180/4484\n",
            "5%: 225/4484\n",
            "6%: 270/4484\n",
            "7%: 314/4484\n",
            "8%: 359/4484\n",
            "9%: 404/4484\n",
            "10%: 449/4484\n",
            "11%: 494/4484\n",
            "12%: 539/4484\n",
            "13%: 583/4484\n",
            "14%: 628/4484\n",
            "15%: 673/4484\n",
            "16%: 718/4484\n",
            "17%: 763/4484\n",
            "18%: 808/4484\n",
            "19%: 852/4484\n",
            "20%: 897/4484\n",
            "21%: 942/4484\n",
            "22%: 987/4484\n",
            "23%: 1032/4484\n",
            "24%: 1077/4484\n",
            "25%: 1121/4484\n",
            "26%: 1166/4484\n",
            "27%: 1211/4484\n",
            "28%: 1256/4484\n",
            "29%: 1301/4484\n",
            "30%: 1346/4484\n",
            "31%: 1391/4484\n",
            "32%: 1435/4484\n",
            "33%: 1480/4484\n",
            "34%: 1525/4484\n",
            "35%: 1570/4484\n",
            "36%: 1615/4484\n",
            "37%: 1660/4484\n",
            "38%: 1704/4484\n",
            "39%: 1749/4484\n",
            "40%: 1794/4484\n",
            "41%: 1839/4484\n",
            "42%: 1884/4484\n",
            "43%: 1929/4484\n",
            "44%: 1973/4484\n",
            "45%: 2018/4484\n",
            "46%: 2063/4484\n",
            "47%: 2108/4484\n",
            "48%: 2153/4484\n",
            "49%: 2198/4484\n",
            "50%: 2242/4484\n",
            "51%: 2287/4484\n",
            "52%: 2332/4484\n",
            "53%: 2377/4484\n",
            "54%: 2422/4484\n",
            "55%: 2467/4484\n",
            "56%: 2512/4484\n",
            "57%: 2556/4484\n",
            "58%: 2601/4484\n",
            "59%: 2646/4484\n",
            "60%: 2691/4484\n",
            "61%: 2736/4484\n",
            "62%: 2781/4484\n",
            "63%: 2825/4484\n",
            "64%: 2870/4484\n",
            "65%: 2915/4484\n",
            "66%: 2960/4484\n",
            "67%: 3005/4484\n",
            "68%: 3050/4484\n",
            "69%: 3094/4484\n",
            "70%: 3139/4484\n",
            "71%: 3184/4484\n",
            "72%: 3229/4484\n",
            "73%: 3274/4484\n",
            "74%: 3319/4484\n",
            "75%: 3363/4484\n",
            "76%: 3408/4484\n",
            "77%: 3453/4484\n",
            "78%: 3498/4484\n",
            "79%: 3543/4484\n",
            "80%: 3588/4484\n",
            "81%: 3633/4484\n",
            "82%: 3677/4484\n",
            "83%: 3722/4484\n",
            "84%: 3767/4484\n",
            "85%: 3812/4484\n",
            "86%: 3857/4484\n",
            "87%: 3902/4484\n",
            "88%: 3946/4484\n",
            "89%: 3991/4484\n",
            "90%: 4036/4484\n",
            "91%: 4081/4484\n",
            "92%: 4126/4484\n",
            "93%: 4171/4484\n",
            "94%: 4215/4484\n",
            "95%: 4260/4484\n",
            "96%: 4305/4484\n",
            "97%: 4350/4484\n",
            "98%: 4395/4484\n",
            "99%: 4440/4484\n",
            "Got 4207 / 4484 correct (93.82)\n",
            "12 epochs: 93.82247992863515\n",
            "Training epoch 3/5\n",
            "t = 100, loss = 1.5192\n",
            "t = 200, loss = 0.0169\n",
            "t = 300, loss = 0.0005\n",
            "t = 400, loss = 3.3101\n",
            "t = 500, loss = 0.0292\n",
            "t = 600, loss = 0.0000\n",
            "t = 700, loss = 0.0000\n",
            "t = 800, loss = 0.0002\n",
            "t = 900, loss = 0.0027\n",
            "t = 1000, loss = 0.0000\n",
            "t = 1100, loss = 1.1559\n",
            "t = 1200, loss = 0.0000\n",
            "t = 1300, loss = 0.0000\n",
            "t = 1400, loss = 0.0627\n",
            "t = 1500, loss = 5.0962\n",
            "t = 1600, loss = 1.3541\n",
            "t = 1700, loss = 9.2361\n",
            "t = 1800, loss = 0.0164\n",
            "t = 1900, loss = 0.0000\n",
            "t = 2000, loss = 0.0030\n",
            "t = 2100, loss = 1.8790\n",
            "t = 2200, loss = 0.6268\n",
            "t = 2300, loss = 0.0012\n",
            "t = 2400, loss = 0.0001\n",
            "t = 2500, loss = 3.7392\n",
            "t = 2600, loss = 0.0747\n",
            "t = 2700, loss = 0.0000\n",
            "t = 2800, loss = 0.0179\n",
            "t = 2900, loss = 0.0000\n",
            "t = 3000, loss = 0.0000\n",
            "t = 3100, loss = 0.0308\n",
            "t = 3200, loss = 0.0346\n",
            "t = 3300, loss = 0.0009\n",
            "t = 3400, loss = 12.2700\n",
            "t = 3500, loss = 0.0000\n",
            "t = 3600, loss = 0.0000\n",
            "t = 3700, loss = 0.0362\n",
            "t = 3800, loss = 0.0970\n",
            "t = 3900, loss = 0.0389\n",
            "t = 4000, loss = 0.0001\n",
            "t = 4100, loss = 0.0004\n",
            "t = 4200, loss = 0.0000\n",
            "t = 4300, loss = 0.0001\n",
            "t = 4400, loss = 0.0000\n",
            "t = 4500, loss = 0.0000\n",
            "t = 4600, loss = 0.1043\n",
            "t = 4700, loss = 1.1107\n",
            "t = 4800, loss = 9.1602\n",
            "t = 4900, loss = 0.2811\n",
            "t = 5000, loss = 0.6995\n",
            "t = 5100, loss = 0.0079\n",
            "t = 5200, loss = 0.0022\n",
            "t = 5300, loss = 0.3584\n",
            "t = 5400, loss = 5.0430\n",
            "t = 5500, loss = 0.0000\n",
            "t = 5600, loss = 0.0014\n",
            "t = 5700, loss = 0.0360\n",
            "t = 5800, loss = 3.5532\n",
            "t = 5900, loss = 0.0025\n",
            "t = 6000, loss = 0.0004\n",
            "t = 6100, loss = 0.0005\n",
            "t = 6200, loss = 0.0000\n",
            "t = 6300, loss = 9.3608\n",
            "t = 6400, loss = 0.0000\n",
            "t = 6500, loss = 3.4058\n",
            "t = 6600, loss = 2.4114\n",
            "t = 6700, loss = 0.1465\n",
            "t = 6800, loss = 0.0001\n",
            "t = 6900, loss = 0.0078\n",
            "t = 7000, loss = 4.9027\n",
            "t = 7100, loss = 0.0023\n",
            "t = 7200, loss = 2.9700\n",
            "t = 7300, loss = 2.2026\n",
            "t = 7400, loss = 0.0003\n",
            "t = 7500, loss = 2.0760\n",
            "t = 7600, loss = 0.0056\n",
            "t = 7700, loss = 3.4001\n",
            "t = 7800, loss = 0.0001\n",
            "t = 7900, loss = 0.0001\n",
            "t = 8000, loss = 0.6008\n",
            "t = 8100, loss = 2.3262\n",
            "t = 8200, loss = 0.0000\n",
            "t = 8300, loss = 11.0432\n",
            "t = 8400, loss = 0.0006\n",
            "t = 8500, loss = 0.0000\n",
            "t = 8600, loss = 0.0004\n",
            "t = 8700, loss = 6.8567\n",
            "t = 8800, loss = 3.4581\n",
            "t = 8900, loss = 2.4716\n",
            "t = 9000, loss = 0.0008\n",
            "t = 9100, loss = 0.0000\n",
            "t = 9200, loss = 0.0295\n",
            "t = 9300, loss = 0.1419\n",
            "t = 9400, loss = 0.0000\n",
            "t = 9500, loss = 0.0000\n",
            "t = 9600, loss = 4.0625\n",
            "t = 9700, loss = 0.0066\n",
            "t = 9800, loss = 5.0979\n",
            "t = 9900, loss = 0.0844\n",
            "t = 10000, loss = 0.0007\n",
            "t = 10100, loss = 0.0081\n",
            "t = 10200, loss = 0.0034\n",
            "t = 10300, loss = 0.0001\n",
            "t = 10400, loss = 0.0084\n",
            "t = 10500, loss = 0.0563\n",
            "t = 10600, loss = 0.0000\n",
            "t = 10700, loss = 0.0000\n",
            "t = 10800, loss = 0.0000\n",
            "t = 10900, loss = 0.0599\n",
            "t = 11000, loss = 0.0001\n",
            "t = 11100, loss = 0.0217\n",
            "t = 11200, loss = 0.0092\n",
            "t = 11300, loss = 0.0001\n",
            "t = 11400, loss = 0.0001\n",
            "t = 11500, loss = 0.0001\n",
            "t = 11600, loss = 0.0001\n",
            "t = 11700, loss = 0.0003\n",
            "t = 11800, loss = 2.6859\n",
            "t = 11900, loss = 0.0002\n",
            "t = 12000, loss = 3.6761\n",
            "t = 12100, loss = 1.7153\n",
            "t = 12200, loss = 11.0714\n",
            "t = 12300, loss = 0.0000\n",
            "t = 12400, loss = 0.0283\n",
            "t = 12500, loss = 0.0001\n",
            "t = 12600, loss = 1.1419\n",
            "t = 12700, loss = 0.0017\n",
            "t = 12800, loss = 0.0000\n",
            "t = 12900, loss = 0.0464\n",
            "t = 13000, loss = 0.0000\n",
            "t = 13100, loss = 23.1349\n",
            "t = 13200, loss = 0.0000\n",
            "t = 13300, loss = 1.3591\n",
            "t = 13400, loss = 0.0000\n",
            "t = 13500, loss = 0.0300\n",
            "t = 13600, loss = 1.3602\n",
            "t = 13700, loss = 0.0972\n",
            "t = 13800, loss = 0.3649\n",
            "t = 13900, loss = 0.0000\n",
            "t = 14000, loss = 0.0000\n",
            "t = 14100, loss = 0.0060\n",
            "t = 14200, loss = 0.0029\n",
            "t = 14300, loss = 0.0000\n",
            "t = 14400, loss = 0.0001\n",
            "t = 14500, loss = 7.3730\n",
            "t = 14600, loss = 0.0017\n",
            "t = 14700, loss = 0.0018\n",
            "t = 14800, loss = 9.9407\n",
            "t = 14900, loss = 0.0032\n",
            "t = 15000, loss = 0.0000\n",
            "t = 15100, loss = 7.0190\n",
            "t = 15200, loss = 0.0000\n",
            "t = 15300, loss = 0.0000\n",
            "t = 15400, loss = 0.0000\n",
            "t = 15500, loss = 0.2365\n",
            "t = 15600, loss = 0.0029\n",
            "t = 15700, loss = 0.3071\n",
            "t = 15800, loss = 0.0000\n",
            "t = 15900, loss = 0.0044\n",
            "t = 16000, loss = 0.0000\n",
            "t = 16100, loss = 0.0001\n",
            "t = 16200, loss = 0.0000\n",
            "t = 16300, loss = 0.0919\n",
            "t = 16400, loss = 0.0000\n",
            "t = 16500, loss = 0.0124\n",
            "t = 16600, loss = 0.0011\n",
            "t = 16700, loss = 0.0000\n",
            "t = 16800, loss = 0.0667\n",
            "t = 16900, loss = 2.2026\n",
            "t = 17000, loss = 0.0033\n",
            "t = 17100, loss = 0.3914\n",
            "t = 17200, loss = 0.0000\n",
            "t = 17300, loss = 5.5756\n",
            "t = 17400, loss = 0.0015\n",
            "t = 17500, loss = 0.0032\n",
            "t = 17600, loss = 0.0004\n",
            "t = 17700, loss = 0.0251\n",
            "t = 17800, loss = 0.0435\n",
            "t = 17900, loss = 0.0000\n",
            "Checking Accuracy\n",
            "1%: 45/4484\n",
            "2%: 90/4484\n",
            "3%: 135/4484\n",
            "4%: 180/4484\n",
            "5%: 225/4484\n",
            "6%: 270/4484\n",
            "7%: 314/4484\n",
            "8%: 359/4484\n",
            "9%: 404/4484\n",
            "10%: 449/4484\n",
            "11%: 494/4484\n",
            "12%: 539/4484\n",
            "13%: 583/4484\n",
            "14%: 628/4484\n",
            "15%: 673/4484\n",
            "16%: 718/4484\n",
            "17%: 763/4484\n",
            "18%: 808/4484\n",
            "19%: 852/4484\n",
            "20%: 897/4484\n",
            "21%: 942/4484\n",
            "22%: 987/4484\n",
            "23%: 1032/4484\n",
            "24%: 1077/4484\n",
            "25%: 1121/4484\n",
            "26%: 1166/4484\n",
            "27%: 1211/4484\n",
            "28%: 1256/4484\n",
            "29%: 1301/4484\n",
            "30%: 1346/4484\n",
            "31%: 1391/4484\n",
            "32%: 1435/4484\n",
            "33%: 1480/4484\n",
            "34%: 1525/4484\n",
            "35%: 1570/4484\n",
            "36%: 1615/4484\n",
            "37%: 1660/4484\n",
            "38%: 1704/4484\n",
            "39%: 1749/4484\n",
            "40%: 1794/4484\n",
            "41%: 1839/4484\n",
            "42%: 1884/4484\n",
            "43%: 1929/4484\n",
            "44%: 1973/4484\n",
            "45%: 2018/4484\n",
            "46%: 2063/4484\n",
            "47%: 2108/4484\n",
            "48%: 2153/4484\n",
            "49%: 2198/4484\n",
            "50%: 2242/4484\n",
            "51%: 2287/4484\n",
            "52%: 2332/4484\n",
            "53%: 2377/4484\n",
            "54%: 2422/4484\n",
            "55%: 2467/4484\n",
            "56%: 2512/4484\n",
            "57%: 2556/4484\n",
            "58%: 2601/4484\n",
            "59%: 2646/4484\n",
            "60%: 2691/4484\n",
            "61%: 2736/4484\n",
            "62%: 2781/4484\n",
            "63%: 2825/4484\n",
            "64%: 2870/4484\n",
            "65%: 2915/4484\n",
            "66%: 2960/4484\n",
            "67%: 3005/4484\n",
            "68%: 3050/4484\n",
            "69%: 3094/4484\n",
            "70%: 3139/4484\n",
            "71%: 3184/4484\n",
            "72%: 3229/4484\n",
            "73%: 3274/4484\n",
            "74%: 3319/4484\n",
            "75%: 3363/4484\n",
            "76%: 3408/4484\n",
            "77%: 3453/4484\n",
            "78%: 3498/4484\n",
            "79%: 3543/4484\n",
            "80%: 3588/4484\n",
            "81%: 3633/4484\n",
            "82%: 3677/4484\n",
            "83%: 3722/4484\n",
            "84%: 3767/4484\n",
            "85%: 3812/4484\n",
            "86%: 3857/4484\n",
            "87%: 3902/4484\n",
            "88%: 3946/4484\n",
            "89%: 3991/4484\n",
            "90%: 4036/4484\n",
            "91%: 4081/4484\n",
            "92%: 4126/4484\n",
            "93%: 4171/4484\n",
            "94%: 4215/4484\n",
            "95%: 4260/4484\n",
            "96%: 4305/4484\n",
            "97%: 4350/4484\n",
            "98%: 4395/4484\n",
            "99%: 4440/4484\n",
            "Got 4160 / 4484 correct (92.77)\n",
            "13 epochs: 92.7743086529884\n",
            "Training epoch 4/5\n",
            "t = 100, loss = 15.8710\n",
            "t = 200, loss = 0.0000\n",
            "t = 300, loss = 0.0018\n",
            "t = 400, loss = 2.4509\n",
            "t = 500, loss = 0.0000\n",
            "t = 600, loss = 0.0356\n",
            "t = 700, loss = 1.9464\n",
            "t = 800, loss = 0.0000\n",
            "t = 900, loss = 0.0000\n",
            "t = 1000, loss = 0.0002\n",
            "t = 1100, loss = 5.6324\n",
            "t = 1200, loss = 0.0005\n",
            "t = 1300, loss = 0.0000\n",
            "t = 1400, loss = 0.0025\n",
            "t = 1500, loss = 0.0000\n",
            "t = 1600, loss = 4.9150\n",
            "t = 1700, loss = 0.0006\n",
            "t = 1800, loss = 2.1361\n",
            "t = 1900, loss = 3.6762\n",
            "t = 2000, loss = 0.0005\n",
            "t = 2100, loss = 0.0001\n",
            "t = 2200, loss = 0.0755\n",
            "t = 2300, loss = 0.0002\n",
            "t = 2400, loss = 0.2866\n",
            "t = 2500, loss = 0.0000\n",
            "t = 2600, loss = 0.0000\n",
            "t = 2700, loss = 27.1849\n",
            "t = 2800, loss = 0.4135\n",
            "t = 2900, loss = 0.0283\n",
            "t = 3000, loss = 0.0003\n",
            "t = 3100, loss = 2.0195\n",
            "t = 3200, loss = 0.0000\n",
            "t = 3300, loss = 0.0000\n",
            "t = 3400, loss = 0.0000\n",
            "t = 3500, loss = 0.0057\n",
            "t = 3600, loss = 4.7712\n",
            "t = 3700, loss = 1.6086\n",
            "t = 3800, loss = 0.0042\n",
            "t = 3900, loss = 0.0089\n",
            "t = 4000, loss = 0.0000\n",
            "t = 4100, loss = 0.0000\n",
            "t = 4200, loss = 0.0621\n",
            "t = 4300, loss = 4.2604\n",
            "t = 4400, loss = 0.0000\n",
            "t = 4500, loss = 0.1359\n",
            "t = 4600, loss = 0.0000\n",
            "t = 4700, loss = 1.9655\n",
            "t = 4800, loss = 0.0550\n",
            "t = 4900, loss = 6.8105\n",
            "t = 5000, loss = 0.0570\n",
            "t = 5100, loss = 0.5396\n",
            "t = 5200, loss = 0.0001\n",
            "t = 5300, loss = 0.0090\n",
            "t = 5400, loss = 0.1505\n",
            "t = 5500, loss = 0.0004\n",
            "t = 5600, loss = 0.0002\n",
            "t = 5700, loss = 0.0201\n",
            "t = 5800, loss = 3.6623\n",
            "t = 5900, loss = 0.0142\n",
            "t = 6000, loss = 10.9569\n",
            "t = 6100, loss = 0.0040\n",
            "t = 6200, loss = 0.0000\n",
            "t = 6300, loss = 0.0001\n",
            "t = 6400, loss = 0.0002\n",
            "t = 6500, loss = 0.0001\n",
            "t = 6600, loss = 0.0001\n",
            "t = 6700, loss = 0.0000\n",
            "t = 6800, loss = 0.7217\n",
            "t = 6900, loss = 2.8272\n",
            "t = 7000, loss = 0.0386\n",
            "t = 7100, loss = 0.0137\n",
            "t = 7200, loss = 0.0638\n",
            "t = 7300, loss = 0.0143\n",
            "t = 7400, loss = 7.3812\n",
            "t = 7500, loss = 4.0395\n",
            "t = 7600, loss = 0.0117\n",
            "t = 7700, loss = 1.1435\n",
            "t = 7800, loss = 0.0000\n",
            "t = 7900, loss = 0.0000\n",
            "t = 8000, loss = 0.0001\n",
            "t = 8100, loss = 0.0005\n",
            "t = 8200, loss = 2.6542\n",
            "t = 8300, loss = 0.0002\n",
            "t = 8400, loss = 0.0004\n",
            "t = 8500, loss = 1.6954\n",
            "t = 8600, loss = 0.0063\n",
            "t = 8700, loss = 8.7777\n",
            "t = 8800, loss = 0.0000\n",
            "t = 8900, loss = 0.2792\n",
            "t = 9000, loss = 10.3437\n",
            "t = 9100, loss = 0.0000\n",
            "t = 9200, loss = 0.0005\n",
            "t = 9300, loss = 0.0041\n",
            "t = 9400, loss = 0.0850\n",
            "t = 9500, loss = 0.0000\n",
            "t = 9600, loss = 0.0068\n",
            "t = 9700, loss = 3.1257\n",
            "t = 9800, loss = 0.0486\n",
            "t = 9900, loss = 0.0007\n",
            "t = 10000, loss = 0.0000\n",
            "t = 10100, loss = 0.0088\n",
            "t = 10200, loss = 0.0005\n",
            "t = 10300, loss = 0.0004\n",
            "t = 10400, loss = 1.0954\n",
            "t = 10500, loss = 2.8788\n",
            "t = 10600, loss = 0.0000\n",
            "t = 10700, loss = 0.0000\n",
            "t = 10800, loss = 0.1062\n",
            "t = 10900, loss = 0.8745\n",
            "t = 11000, loss = 0.1628\n",
            "t = 11100, loss = 0.0450\n",
            "t = 11200, loss = 0.0004\n",
            "t = 11300, loss = 5.2025\n",
            "t = 11400, loss = 0.0001\n",
            "t = 11500, loss = 0.0021\n",
            "t = 11600, loss = 0.0771\n",
            "t = 11700, loss = 0.0036\n",
            "t = 11800, loss = 0.0000\n",
            "t = 11900, loss = 0.0123\n",
            "t = 12000, loss = 0.0020\n",
            "t = 12100, loss = 0.0000\n",
            "t = 12200, loss = 0.0007\n",
            "t = 12300, loss = 0.7839\n",
            "t = 12400, loss = 0.0000\n",
            "t = 12500, loss = 0.0008\n",
            "t = 12600, loss = 0.0948\n",
            "t = 12700, loss = 0.0000\n",
            "t = 12800, loss = 0.0000\n",
            "t = 12900, loss = 7.5184\n",
            "t = 13000, loss = 0.0001\n",
            "t = 13100, loss = 1.9013\n",
            "t = 13200, loss = 2.1789\n",
            "t = 13300, loss = 0.0021\n",
            "t = 13400, loss = 0.0000\n",
            "t = 13500, loss = 1.9710\n",
            "t = 13600, loss = 2.1813\n",
            "t = 13700, loss = 0.0159\n",
            "t = 13800, loss = 14.5770\n",
            "t = 13900, loss = 0.0000\n",
            "t = 14000, loss = 0.0000\n",
            "t = 14100, loss = 0.0014\n",
            "t = 14200, loss = 0.0016\n",
            "t = 14300, loss = 0.0001\n",
            "t = 14400, loss = 0.0222\n",
            "t = 14500, loss = 0.1505\n",
            "t = 14600, loss = 2.3758\n",
            "t = 14700, loss = 2.1596\n",
            "t = 14800, loss = 0.0005\n",
            "t = 14900, loss = 2.5643\n",
            "t = 15000, loss = 3.1994\n",
            "t = 15100, loss = 0.0000\n",
            "t = 15200, loss = 0.0005\n",
            "t = 15300, loss = 1.9174\n",
            "t = 15400, loss = 0.0027\n",
            "t = 15500, loss = 6.1737\n",
            "t = 15600, loss = 19.0220\n",
            "t = 15700, loss = 0.0003\n",
            "t = 15800, loss = 3.4977\n",
            "t = 15900, loss = 0.0423\n",
            "t = 16000, loss = 0.0011\n",
            "t = 16100, loss = 5.2242\n",
            "t = 16200, loss = 0.0709\n",
            "t = 16300, loss = 1.2314\n",
            "t = 16400, loss = 0.0000\n",
            "t = 16500, loss = 0.3437\n",
            "t = 16600, loss = 0.1105\n",
            "t = 16700, loss = 3.6338\n",
            "t = 16800, loss = 0.0557\n",
            "t = 16900, loss = 0.0000\n",
            "t = 17000, loss = 0.0004\n",
            "t = 17100, loss = 0.0002\n",
            "t = 17200, loss = 0.0108\n",
            "t = 17300, loss = 3.9073\n",
            "t = 17400, loss = 7.1990\n",
            "t = 17500, loss = 0.0424\n",
            "t = 17600, loss = 0.0010\n",
            "t = 17700, loss = 0.0001\n",
            "t = 17800, loss = 0.0556\n",
            "t = 17900, loss = 0.0000\n",
            "Checking Accuracy\n",
            "1%: 45/4484\n",
            "2%: 90/4484\n",
            "3%: 135/4484\n",
            "4%: 180/4484\n",
            "5%: 225/4484\n",
            "6%: 270/4484\n",
            "7%: 314/4484\n",
            "8%: 359/4484\n",
            "9%: 404/4484\n",
            "10%: 449/4484\n",
            "11%: 494/4484\n",
            "12%: 539/4484\n",
            "13%: 583/4484\n",
            "14%: 628/4484\n",
            "15%: 673/4484\n",
            "16%: 718/4484\n",
            "17%: 763/4484\n",
            "18%: 808/4484\n",
            "19%: 852/4484\n",
            "20%: 897/4484\n",
            "21%: 942/4484\n",
            "22%: 987/4484\n",
            "23%: 1032/4484\n",
            "24%: 1077/4484\n",
            "25%: 1121/4484\n",
            "26%: 1166/4484\n",
            "27%: 1211/4484\n",
            "28%: 1256/4484\n",
            "29%: 1301/4484\n",
            "30%: 1346/4484\n",
            "31%: 1391/4484\n",
            "32%: 1435/4484\n",
            "33%: 1480/4484\n",
            "34%: 1525/4484\n",
            "35%: 1570/4484\n",
            "36%: 1615/4484\n",
            "37%: 1660/4484\n",
            "38%: 1704/4484\n",
            "39%: 1749/4484\n",
            "40%: 1794/4484\n",
            "41%: 1839/4484\n",
            "42%: 1884/4484\n",
            "43%: 1929/4484\n",
            "44%: 1973/4484\n",
            "45%: 2018/4484\n",
            "46%: 2063/4484\n",
            "47%: 2108/4484\n",
            "48%: 2153/4484\n",
            "49%: 2198/4484\n",
            "50%: 2242/4484\n",
            "51%: 2287/4484\n",
            "52%: 2332/4484\n",
            "53%: 2377/4484\n",
            "54%: 2422/4484\n",
            "55%: 2467/4484\n",
            "56%: 2512/4484\n",
            "57%: 2556/4484\n",
            "58%: 2601/4484\n",
            "59%: 2646/4484\n",
            "60%: 2691/4484\n",
            "61%: 2736/4484\n",
            "62%: 2781/4484\n",
            "63%: 2825/4484\n",
            "64%: 2870/4484\n",
            "65%: 2915/4484\n",
            "66%: 2960/4484\n",
            "67%: 3005/4484\n",
            "68%: 3050/4484\n",
            "69%: 3094/4484\n",
            "70%: 3139/4484\n",
            "71%: 3184/4484\n",
            "72%: 3229/4484\n",
            "73%: 3274/4484\n",
            "74%: 3319/4484\n",
            "75%: 3363/4484\n",
            "76%: 3408/4484\n",
            "77%: 3453/4484\n",
            "78%: 3498/4484\n",
            "79%: 3543/4484\n",
            "80%: 3588/4484\n",
            "81%: 3633/4484\n",
            "82%: 3677/4484\n",
            "83%: 3722/4484\n",
            "84%: 3767/4484\n",
            "85%: 3812/4484\n",
            "86%: 3857/4484\n",
            "87%: 3902/4484\n",
            "88%: 3946/4484\n",
            "89%: 3991/4484\n",
            "90%: 4036/4484\n",
            "91%: 4081/4484\n",
            "92%: 4126/4484\n",
            "93%: 4171/4484\n",
            "94%: 4215/4484\n",
            "95%: 4260/4484\n",
            "96%: 4305/4484\n",
            "97%: 4350/4484\n",
            "98%: 4395/4484\n",
            "99%: 4440/4484\n",
            "Got 4219 / 4484 correct (94.09)\n",
            "14 epochs: 94.09009812667261\n",
            "Training epoch 5/5\n",
            "t = 100, loss = 0.0000\n",
            "t = 200, loss = 7.7432\n",
            "t = 300, loss = 0.0553\n",
            "t = 400, loss = 0.0103\n",
            "t = 500, loss = 0.6238\n",
            "t = 600, loss = 22.9861\n",
            "t = 700, loss = 0.0000\n",
            "t = 800, loss = 0.0000\n",
            "t = 900, loss = 6.6282\n",
            "t = 1000, loss = 0.0000\n",
            "t = 1100, loss = 0.2772\n",
            "t = 1200, loss = 0.0001\n",
            "t = 1300, loss = 0.5280\n",
            "t = 1400, loss = 0.1633\n",
            "t = 1500, loss = 0.0158\n",
            "t = 1600, loss = 0.3297\n",
            "t = 1700, loss = 0.5974\n",
            "t = 1800, loss = 0.0001\n",
            "t = 1900, loss = 0.0106\n",
            "t = 2000, loss = 2.0307\n",
            "t = 2100, loss = 3.6141\n",
            "t = 2200, loss = 1.7141\n",
            "t = 2300, loss = 0.0000\n",
            "t = 2400, loss = 0.0001\n",
            "t = 2500, loss = 0.0010\n",
            "t = 2600, loss = 0.0000\n",
            "t = 2700, loss = 0.0004\n",
            "t = 2800, loss = 0.0000\n",
            "t = 2900, loss = 0.0000\n",
            "t = 3000, loss = 0.0000\n",
            "t = 3100, loss = 0.0658\n",
            "t = 3200, loss = 0.0000\n",
            "t = 3300, loss = 0.8082\n",
            "t = 3400, loss = 0.0012\n",
            "t = 3500, loss = 0.0000\n",
            "t = 3600, loss = 0.0117\n",
            "t = 3700, loss = 0.0000\n",
            "t = 3800, loss = 0.0400\n",
            "t = 3900, loss = 0.0008\n",
            "t = 4000, loss = 2.4474\n",
            "t = 4100, loss = 0.0001\n",
            "t = 4200, loss = 0.0245\n",
            "t = 4300, loss = 11.1409\n",
            "t = 4400, loss = 0.0001\n",
            "t = 4500, loss = 0.0037\n",
            "t = 4600, loss = 0.0001\n",
            "t = 4700, loss = 0.0002\n",
            "t = 4800, loss = 0.1731\n",
            "t = 4900, loss = 0.6236\n",
            "t = 5000, loss = 0.0000\n",
            "t = 5100, loss = 3.1741\n",
            "t = 5200, loss = 0.0000\n",
            "t = 5300, loss = 0.0000\n",
            "t = 5400, loss = 0.0005\n",
            "t = 5500, loss = 0.0000\n",
            "t = 5600, loss = 0.0748\n",
            "t = 5700, loss = 0.0001\n",
            "t = 5800, loss = 4.9955\n",
            "t = 5900, loss = 0.0033\n",
            "t = 6000, loss = 0.0070\n",
            "t = 6100, loss = 6.0226\n",
            "t = 6200, loss = 0.0002\n",
            "t = 6300, loss = 0.4598\n",
            "t = 6400, loss = 0.0032\n",
            "t = 6500, loss = 0.0237\n",
            "t = 6600, loss = 0.5482\n",
            "t = 6700, loss = 0.0000\n",
            "t = 6800, loss = 0.0002\n",
            "t = 6900, loss = 0.0000\n",
            "t = 7000, loss = 3.8756\n",
            "t = 7100, loss = 0.0602\n",
            "t = 7200, loss = 0.0558\n",
            "t = 7300, loss = 0.0000\n",
            "t = 7400, loss = 0.0000\n",
            "t = 7500, loss = 0.0000\n",
            "t = 7600, loss = 0.2521\n",
            "t = 7700, loss = 0.0014\n",
            "t = 7800, loss = 0.0000\n",
            "t = 7900, loss = 0.0018\n",
            "t = 8000, loss = 0.1911\n",
            "t = 8100, loss = 0.0006\n",
            "t = 8200, loss = 0.0000\n",
            "t = 8300, loss = 0.0000\n",
            "t = 8400, loss = 0.2899\n",
            "t = 8500, loss = 0.0000\n",
            "t = 8600, loss = 0.0000\n",
            "t = 8700, loss = 0.0000\n",
            "t = 8800, loss = 0.0001\n",
            "t = 8900, loss = 0.0046\n",
            "t = 9000, loss = 0.0000\n",
            "t = 9100, loss = 0.0536\n",
            "t = 9200, loss = 7.4117\n",
            "t = 9300, loss = 8.1592\n",
            "t = 9400, loss = 0.0002\n",
            "t = 9500, loss = 13.5820\n",
            "t = 9600, loss = 0.0067\n",
            "t = 9700, loss = 4.7900\n",
            "t = 9800, loss = 0.0034\n",
            "t = 9900, loss = 0.0174\n",
            "t = 10000, loss = 0.1060\n",
            "t = 10100, loss = 0.0070\n",
            "t = 10200, loss = 0.0001\n",
            "t = 10300, loss = 0.2623\n",
            "t = 10400, loss = 0.0000\n",
            "t = 10500, loss = 2.5881\n",
            "t = 10600, loss = 0.0000\n",
            "t = 10700, loss = 0.0976\n",
            "t = 10800, loss = 3.0390\n",
            "t = 10900, loss = 0.0013\n",
            "t = 11000, loss = 0.0005\n",
            "t = 11100, loss = 0.0007\n",
            "t = 11200, loss = 8.3133\n",
            "t = 11300, loss = 0.0000\n",
            "t = 11400, loss = 0.0000\n",
            "t = 11500, loss = 0.0114\n",
            "t = 11600, loss = 0.0167\n",
            "t = 11700, loss = 0.0000\n",
            "t = 11800, loss = 0.0555\n",
            "t = 11900, loss = 0.0269\n",
            "t = 12000, loss = 0.0000\n",
            "t = 12100, loss = 0.0204\n",
            "t = 12200, loss = 0.7678\n",
            "t = 12300, loss = 0.0002\n",
            "t = 12400, loss = 0.0010\n",
            "t = 12500, loss = 0.0000\n",
            "t = 12600, loss = 0.0709\n",
            "t = 12700, loss = 0.0000\n",
            "t = 12800, loss = 24.2979\n",
            "t = 12900, loss = 0.0533\n",
            "t = 13000, loss = 0.0029\n",
            "t = 13100, loss = 0.0143\n",
            "t = 13200, loss = 0.0701\n",
            "t = 13300, loss = 0.0000\n",
            "t = 13400, loss = 14.9495\n",
            "t = 13500, loss = 11.0953\n",
            "t = 13600, loss = 0.0049\n",
            "t = 13700, loss = 0.5360\n",
            "t = 13800, loss = 1.4327\n",
            "t = 13900, loss = 0.2597\n",
            "t = 14000, loss = 0.0000\n",
            "t = 14100, loss = 0.0000\n",
            "t = 14200, loss = 0.0013\n",
            "t = 14300, loss = 0.0574\n",
            "t = 14400, loss = 4.1552\n",
            "t = 14500, loss = 1.4386\n",
            "t = 14600, loss = 1.3495\n",
            "t = 14700, loss = 6.9520\n",
            "t = 14800, loss = 0.0005\n",
            "t = 14900, loss = 0.0012\n",
            "t = 15000, loss = 0.1133\n",
            "t = 15100, loss = 0.1383\n",
            "t = 15200, loss = 0.0000\n",
            "t = 15300, loss = 0.0000\n",
            "t = 15400, loss = 0.1277\n",
            "t = 15500, loss = 0.0020\n",
            "t = 15600, loss = 0.0001\n",
            "t = 15700, loss = 0.0000\n",
            "t = 15800, loss = 0.6599\n",
            "t = 15900, loss = 0.0313\n",
            "t = 16000, loss = 0.0416\n",
            "t = 16100, loss = 1.2450\n",
            "t = 16200, loss = 2.6157\n",
            "t = 16300, loss = 0.0001\n",
            "t = 16400, loss = 0.1098\n",
            "t = 16500, loss = 3.0347\n",
            "t = 16600, loss = 0.0137\n",
            "t = 16700, loss = 0.0000\n",
            "t = 16800, loss = 0.0063\n",
            "t = 16900, loss = 0.0072\n",
            "t = 17000, loss = 4.7158\n",
            "t = 17100, loss = 3.0428\n",
            "t = 17200, loss = 3.9384\n",
            "t = 17300, loss = 0.2305\n",
            "t = 17400, loss = 0.0001\n",
            "t = 17500, loss = 0.0034\n",
            "t = 17600, loss = 1.1746\n",
            "t = 17700, loss = 0.0715\n",
            "t = 17800, loss = 0.0385\n",
            "t = 17900, loss = 0.0000\n",
            "Checking Accuracy\n",
            "1%: 45/4484\n",
            "2%: 90/4484\n",
            "3%: 135/4484\n",
            "4%: 180/4484\n",
            "5%: 225/4484\n",
            "6%: 270/4484\n",
            "7%: 314/4484\n",
            "8%: 359/4484\n",
            "9%: 404/4484\n",
            "10%: 449/4484\n",
            "11%: 494/4484\n",
            "12%: 539/4484\n",
            "13%: 583/4484\n",
            "14%: 628/4484\n",
            "15%: 673/4484\n",
            "16%: 718/4484\n",
            "17%: 763/4484\n",
            "18%: 808/4484\n",
            "19%: 852/4484\n",
            "20%: 897/4484\n",
            "21%: 942/4484\n",
            "22%: 987/4484\n",
            "23%: 1032/4484\n",
            "24%: 1077/4484\n",
            "25%: 1121/4484\n",
            "26%: 1166/4484\n",
            "27%: 1211/4484\n",
            "28%: 1256/4484\n",
            "29%: 1301/4484\n",
            "30%: 1346/4484\n",
            "31%: 1391/4484\n",
            "32%: 1435/4484\n",
            "33%: 1480/4484\n",
            "34%: 1525/4484\n",
            "35%: 1570/4484\n",
            "36%: 1615/4484\n",
            "37%: 1660/4484\n",
            "38%: 1704/4484\n",
            "39%: 1749/4484\n",
            "40%: 1794/4484\n",
            "41%: 1839/4484\n",
            "42%: 1884/4484\n",
            "43%: 1929/4484\n",
            "44%: 1973/4484\n",
            "45%: 2018/4484\n",
            "46%: 2063/4484\n",
            "47%: 2108/4484\n",
            "48%: 2153/4484\n",
            "49%: 2198/4484\n",
            "50%: 2242/4484\n",
            "51%: 2287/4484\n",
            "52%: 2332/4484\n",
            "53%: 2377/4484\n",
            "54%: 2422/4484\n",
            "55%: 2467/4484\n",
            "56%: 2512/4484\n",
            "57%: 2556/4484\n",
            "58%: 2601/4484\n",
            "59%: 2646/4484\n",
            "60%: 2691/4484\n",
            "61%: 2736/4484\n",
            "62%: 2781/4484\n",
            "63%: 2825/4484\n",
            "64%: 2870/4484\n",
            "65%: 2915/4484\n",
            "66%: 2960/4484\n",
            "67%: 3005/4484\n",
            "68%: 3050/4484\n",
            "69%: 3094/4484\n",
            "70%: 3139/4484\n",
            "71%: 3184/4484\n",
            "72%: 3229/4484\n",
            "73%: 3274/4484\n",
            "74%: 3319/4484\n",
            "75%: 3363/4484\n",
            "76%: 3408/4484\n",
            "77%: 3453/4484\n",
            "78%: 3498/4484\n",
            "79%: 3543/4484\n",
            "80%: 3588/4484\n",
            "81%: 3633/4484\n",
            "82%: 3677/4484\n",
            "83%: 3722/4484\n",
            "84%: 3767/4484\n",
            "85%: 3812/4484\n",
            "86%: 3857/4484\n",
            "87%: 3902/4484\n",
            "88%: 3946/4484\n",
            "89%: 3991/4484\n",
            "90%: 4036/4484\n",
            "91%: 4081/4484\n",
            "92%: 4126/4484\n",
            "93%: 4171/4484\n",
            "94%: 4215/4484\n",
            "95%: 4260/4484\n",
            "96%: 4305/4484\n",
            "97%: 4350/4484\n",
            "98%: 4395/4484\n",
            "99%: 4440/4484\n",
            "Got 4240 / 4484 correct (94.56)\n",
            "15 epochs: 94.55842997323818\n",
            "Save Model? (Y/N): y\n",
            "Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbbcn-Dx_aWl",
        "colab_type": "code",
        "outputId": "c8b9de66-83cd-4486-a933-ae947739d53d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "def plot_validation(validation):\n",
        "  l = []\n",
        "  for i in validation.values():\n",
        "    l.append(i)\n",
        "  x_range = range(1,max(validation.keys())+1)\n",
        "  plt.plot(x_range, l)\n",
        "  plt.title('Validations')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xticks(x_range)\n",
        "  plt.grid()\n",
        "plot_validation(validation)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eStFCV26P5dN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}